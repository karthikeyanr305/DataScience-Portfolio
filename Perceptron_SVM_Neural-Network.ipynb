{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a9813d1",
   "metadata": {
    "id": "2a9813d1"
   },
   "source": [
    "# Perceptron, SVM, and Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f0421a",
   "metadata": {
    "id": "45f0421a"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JmMLz83F5rja",
   "metadata": {
    "id": "JmMLz83F5rja"
   },
   "source": [
    "# 1. Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2IBreuJnmsvB",
   "metadata": {
    "id": "2IBreuJnmsvB"
   },
   "outputs": [],
   "source": [
    "# import the assigned dataset\n",
    "df = pd.read_csv('telescope.csv')\n",
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a5fa5da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3a5fa5da",
    "outputId": "ea2c14e7-bf3f-43ab-d612-72885be97f22",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-39871c3e-8798-4b6e-9d47-a2ba25336203\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39871c3e-8798-4b6e-9d47-a2ba25336203')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-39871c3e-8798-4b6e-9d47-a2ba25336203 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-39871c3e-8798-4b6e-9d47-a2ba25336203');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
       "\n",
       "  targets  \n",
       "0       g  \n",
       "1       g  \n",
       "2       g  \n",
       "3       g  \n",
       "4       g  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "570eedf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "570eedf2",
    "outputId": "1c83fb08-73bf-45fb-8d32-a3dd5f5713dd",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'targets'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca4fdec",
   "metadata": {
    "id": "fca4fdec"
   },
   "outputs": [],
   "source": [
    "target_list = []\n",
    "for row in df['targets']:\n",
    "    if row == 'g':\n",
    "        target_list.append(float(0))\n",
    "    else:\n",
    "        target_list.append(float(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfff0c8b",
   "metadata": {
    "id": "dfff0c8b"
   },
   "outputs": [],
   "source": [
    "df['targets_float'] = target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "D6LXkVd1mtJh",
   "metadata": {
    "id": "D6LXkVd1mtJh"
   },
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "\n",
    "df_x = df[[\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\"]]\n",
    "#df_x = df.columns[:-1]\n",
    "\n",
    "df_y = df[['targets_float']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "LIwB8dmYq9iH",
   "metadata": {
    "id": "LIwB8dmYq9iH"
   },
   "outputs": [],
   "source": [
    "# Make a train-test split with 80% to training and 20% to testing.\n",
    "from sklearn.model_selection import train_test_split\n",
    "features = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\"]\n",
    "telescopex_train, telescopex_test, telescopey_train, telescopey_test = train_test_split( df_x,\n",
    "                                                                        df_y, test_size=0.2, random_state = 4)#, stratify = df_mushrooms_v2['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2g0SCXkcmtML",
   "metadata": {
    "id": "2g0SCXkcmtML"
   },
   "outputs": [],
   "source": [
    "# Normalize numerical features and encode the categorical features (if any)\n",
    "train_x_std = StandardScaler().fit_transform(telescopex_train)\n",
    "test_x_std = StandardScaler().fit_transform(telescopex_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b908905e",
   "metadata": {
    "id": "b908905e"
   },
   "outputs": [],
   "source": [
    "train_y = telescopey_train\n",
    "test_y = telescopey_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936fab42",
   "metadata": {
    "id": "936fab42"
   },
   "source": [
    "As this is a classification problem, the target variables must be categorical. Using the feature and target variable information, preprocess the dataset to use given features.\n",
    "\n",
    "This step might require students to scale the features, one-hot encode categorical FEATURES (if any).\n",
    "\n",
    "\n",
    "\n",
    "For feature scaling and one-hot encoding, go through:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204d3db",
   "metadata": {
    "id": "a204d3db"
   },
   "source": [
    "# 2: Creating a perceptron model for the processed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0014b24",
   "metadata": {
    "id": "b0014b24"
   },
   "source": [
    "The perceptron.py file in the resources provides functions to code the perceptron model from scratch.\n",
    "\n",
    "Using the file as reference, write the functions:\n",
    "\n",
    "1. cross_validation_split\n",
    "2. accuracy_metric\n",
    "3. evaluate_algorithm\n",
    "4. predict\n",
    "5. train_weights\n",
    "6. perceptron\n",
    "\n",
    "This step is aimed at providing a comprehensive understanding of the internal functioning of a perceptron model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b7429d7c",
   "metadata": {
    "id": "b7429d7c"
   },
   "outputs": [],
   "source": [
    "# your code for step 2\n",
    "\n",
    "from random import randrange\n",
    "# Split a dataset into k folds\n",
    "\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    #print(\"dataset------------\",dataset_split)\n",
    "    return dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    #print(\"evaluate_algo---------folds\",  type(folds))\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        #print(\"train_set ---------\",  train_set )\n",
    "        #print(\"\\n fold ---------\",  fold)\n",
    "        train_set.remove(fold)\n",
    "        #print(\"\\n train_set after remove ---------\",  fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "# Make a prediction with weights\n",
    "def predict(row, weights):\n",
    "    activation = weights[0]\n",
    "    for i in range(len(row)-1):\n",
    "        activation += weights[i + 1] * row[i]\n",
    "    return 1.0 if activation >= 0.0 else 0.0\n",
    "\n",
    "# Estimate Perceptron weights using stochastic gradient descent\n",
    "def train_weights(train, l_rate, n_epoch):\n",
    "    #print(train, \"train_weight-----------\")\n",
    "    weights = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        for row in train:\n",
    "            prediction = predict(row, weights)\n",
    "            error = row[-1] - prediction\n",
    "            weights[0] = weights[0] + l_rate * error\n",
    "            for i in range(len(row)-1):\n",
    "                weights[i + 1] = weights[i + 1] + l_rate * error * row[i]\n",
    "    return weights\n",
    "\n",
    "# Perceptron Algorithm With Stochastic Gradient Descent\n",
    "def perceptron(train, test, l_rate, n_epoch):\n",
    "    #print(\"perceptron----\" , \"train-----------\", train)\n",
    "    #print(\"perceptron----\" , \"test-----------\", test)\n",
    "    predictions = list()\n",
    "    #print(train, \"perceptron --------\")\n",
    "    weights = train_weights(train, l_rate, n_epoch)\n",
    "    for row in test:\n",
    "        prediction = predict(row, weights)\n",
    "        predictions.append(prediction)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b79cbb",
   "metadata": {
    "id": "95b79cbb"
   },
   "source": [
    "# 3: Batch size for perceptron model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27d5b9",
   "metadata": {
    "id": "6d27d5b9"
   },
   "source": [
    "Experiment with different batch sizes in the perceptron model (eg: 1, 4, 8).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "65f8b124",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65f8b124",
    "outputId": "ac3850cc-74ca-47b9-cb76-235357d8e55c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [69.61750788643532, 64.43217665615141, 68.88801261829653]\n",
      "Mean Accuracy: 67.646%\n"
     ]
    }
   ],
   "source": [
    "# code for step 3\n",
    "n_folds1 = 3\n",
    "l_rate = 0.01\n",
    "n_epoch = 500\n",
    "dataset = np.hstack((train_x_std, train_y))\n",
    "dataset = dataset.tolist()\n",
    "scores = evaluate_algorithm(dataset, perceptron, n_folds1, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6572ca2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6572ca2f",
    "outputId": "23bb8eaf-3b5f-49c0-e866-178aba1f1f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [61.715412421952024, 62.8984554715741, 55.14295103516267, 58.166283273085774, 44.6927374301676]\n",
      "Mean Accuracy: 56.523%\n"
     ]
    }
   ],
   "source": [
    "# code for step 3\n",
    "n_folds2 = 5\n",
    "l_rate = 0.01\n",
    "n_epoch = 500\n",
    "dataset = np.hstack((train_x_std, train_y))\n",
    "dataset = dataset.tolist()\n",
    "scores = evaluate_algorithm(dataset, perceptron, n_folds2, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "VBCOjJts5QvA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBCOjJts5QvA",
    "outputId": "12d7f58d-bfe2-4ca6-b995-ca36405d2be9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [64.88725264611136, 60.51541647491947, 57.57017947537966, 63.368614818223655, 61.84997699033594, 61.71191900598251, 62.724344224574324]\n",
      "Mean Accuracy: 61.804%\n"
     ]
    }
   ],
   "source": [
    "# code for step 3\n",
    "\n",
    "n_folds2 = 7\n",
    "l_rate = 0.01\n",
    "n_epoch = 500\n",
    "dataset = np.hstack((train_x_std, train_y))\n",
    "dataset = dataset.tolist()\n",
    "scores = evaluate_algorithm(dataset, perceptron, n_folds2, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wSYUKCg8neAH",
   "metadata": {
    "id": "wSYUKCg8neAH"
   },
   "source": [
    "# 4. SVM's\n",
    "\n",
    "### **Note : You are allowed to use sklearn's SVC classifier for steps 4.1 through 4.3**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dESPXbsWuF26",
   "metadata": {
    "id": "dESPXbsWuF26"
   },
   "source": [
    "# 4.1 Linear SVM\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Step 1: Implement a linear SVM model to classify the data points. (Look into the 'kernel' parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "GPZt7zZCmtPK",
   "metadata": {
    "id": "GPZt7zZCmtPK"
   },
   "outputs": [],
   "source": [
    "# linear SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "Q5m_V3Z2cbUj",
   "metadata": {
    "id": "Q5m_V3Z2cbUj"
   },
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wDG07yCYt1B0",
   "metadata": {
    "id": "wDG07yCYt1B0"
   },
   "source": [
    "# Step 2: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "xRGroMUFt1J5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRGroMUFt1J5",
    "outputId": "ed00f1ff-86b9-466e-eda1-78fd1855d489"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training - linear SVM\n",
    "svm_clf.fit(train_x_std, train_y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aXe9XNrkDM",
   "metadata": {
    "id": "c2aXe9XNrkDM"
   },
   "source": [
    "# Step 3: Predict for the test points using the model trained in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18yLtskurkMR",
   "metadata": {
    "id": "18yLtskurkMR"
   },
   "outputs": [],
   "source": [
    "# predict - linear SVM\n",
    "linear_svm_pred = svm_clf.predict(test_x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RoR12SgBpzja",
   "metadata": {
    "id": "RoR12SgBpzja"
   },
   "source": [
    "# 4.2 Kernel SVM - Polynomial kernel\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Implement a kernel SVM model with a polynomial kernel to classify the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "lyDOfuYXp7dG",
   "metadata": {
    "id": "lyDOfuYXp7dG"
   },
   "outputs": [],
   "source": [
    "# kernel SVM - polynomial kernel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#create a pipeline to create features, scale data and fit the model\n",
    "polynomial_svm_clf = Pipeline((\n",
    "    (\"poly_features\", PolynomialFeatures(degree=3)),\n",
    "    (\"scalar\", StandardScaler()),\n",
    "    (\"svm_clf\", SVC(kernel=\"poly\", degree=10, coef0=1, C=5)) \n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GpP79PDauc2p",
   "metadata": {
    "id": "GpP79PDauc2p"
   },
   "source": [
    "# Step 2: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "uS6lHWUhuc_X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uS6lHWUhuc_X",
    "outputId": "8dda369e-27a8-4c20-c966-b66bb175712f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('poly_features', PolynomialFeatures(degree=3)),\n",
       "                ('scalar', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=5, coef0=1, degree=10, kernel='poly'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training - kernel SVM\n",
    "polynomial_svm_clf.fit(train_x_std, train_y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eGEDVYRr7hz",
   "metadata": {
    "id": "5eGEDVYRr7hz"
   },
   "source": [
    "# Step 3: Predict for the test points using the model trained in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2CS_FKsr7pF",
   "metadata": {
    "id": "c2CS_FKsr7pF"
   },
   "outputs": [],
   "source": [
    "# predict - kernel SVM\n",
    "poly_svm_pred = polynomial_svm_clf.predict(test_x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BsKcw44Vp7sd",
   "metadata": {
    "id": "BsKcw44Vp7sd"
   },
   "source": [
    "# 4.3 Kernel SVM - Gaussian kernel\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Implement a kernel SVM model with a gaussian (Radian Basis function) kernel to classify the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4nLNaT5SqR58",
   "metadata": {
    "id": "4nLNaT5SqR58"
   },
   "outputs": [],
   "source": [
    "# kernel SVM - gaussian kernel\n",
    "\n",
    "gaussian_svm_clf = Pipeline((\n",
    "    (\"poly_features\", PolynomialFeatures(degree=3)),\n",
    "    (\"scalar\", StandardScaler()),\n",
    "    (\"svm_clf\", SVC(kernel=\"rbf\", degree=10, coef0=1, C=5)) \n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QO82alm_unrk",
   "metadata": {
    "id": "QO82alm_unrk"
   },
   "source": [
    "# Step 2: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "XRlivJbkunys",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRlivJbkunys",
    "outputId": "a0e59bff-718f-48c7-8ca8-ca7800e36c37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('poly_features', PolynomialFeatures(degree=3)),\n",
       "                ('scalar', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=5, coef0=1, degree=10))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training - kernel SVM\n",
    "gaussian_svm_clf.fit(train_x_std,train_y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YCEodCuXr_oi",
   "metadata": {
    "id": "YCEodCuXr_oi"
   },
   "source": [
    "# Step 3: Predict for the test points using the model trained in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "euFQqnXrr_vz",
   "metadata": {
    "id": "euFQqnXrr_vz"
   },
   "outputs": [],
   "source": [
    "# predict - kernel SVM\n",
    "gauss_svm_pred = gaussian_svm_clf.predict(test_x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D4rej5nCsE3e",
   "metadata": {
    "id": "D4rej5nCsE3e"
   },
   "source": [
    "# 4.4 - Evaluation\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Comparing the accuracies of different SVM models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "huEssd0Cs4Su",
   "metadata": {
    "id": "huEssd0Cs4Su"
   },
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "Mbb7piNhvmz7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mbb7piNhvmz7",
    "outputId": "2f42a240-0574-4c44-a25f-e75d4e82519e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------Accuracy------------------------------------------ \n",
      "\n",
      "Accuracy of Linear SVM predictions:\t\t 73.02839116719242 %\n",
      "\n",
      "Accuracy of Polynomial Kernel SVM predictions:\t 79.07465825446897 %\n",
      "\n",
      "Accuracy of Gaussian Kernel SVM predictions:\t 78.04942166140904 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# space for any imports for the following steps\n",
    "actual_y = test_y.values.tolist()\n",
    "\n",
    "linear_svm_accuracy = accuracy_metric(actual_y,linear_svm_pred)\n",
    "poly_svm_accuracy = accuracy_metric(actual_y,poly_svm_pred)\n",
    "gauss_svm_accuracy = accuracy_metric(actual_y,gauss_svm_pred)\n",
    "\n",
    "print(\"------------------------------------------Accuracy------------------------------------------ \\n\")\n",
    "print(\"Accuracy of Linear SVM predictions:\\t\\t {} %\\n\".format(linear_svm_accuracy))\n",
    "print(\"Accuracy of Polynomial Kernel SVM predictions:\\t {} %\\n\".format(poly_svm_accuracy))\n",
    "print(\"Accuracy of Gaussian Kernel SVM predictions:\\t {} %\\n\".format(gauss_svm_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yspPihkdtYzW",
   "metadata": {
    "id": "yspPihkdtYzW"
   },
   "source": [
    "# 5. Neural Networks\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DORVXa96vcl9",
   "metadata": {
    "id": "DORVXa96vcl9"
   },
   "source": [
    "# 5.1 Single layer neural network\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Step 1: Implement a single layer neural network to classify the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "Eekz2V1OvWq8",
   "metadata": {
    "id": "Eekz2V1OvWq8"
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cHXMDpkorn3W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHXMDpkorn3W",
    "outputId": "65fa658d-cf67-427f-9bdc-ff1188b6c8ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "JgolAy-Jkc4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgolAy-Jkc4b",
    "outputId": "932bb2d5-9e4e-497f-efed-7352cb421fef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp0bteenln\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[8])]\n",
    "\n",
    "dnn_clf = tf.estimator.DNNClassifier(hidden_units=[200], n_classes=2,\n",
    "                                     feature_columns=feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9V0qytGdvYTx",
   "metadata": {
    "id": "9V0qytGdvYTx"
   },
   "source": [
    "# Step 2: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "y6EOwJ70vYaD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6EOwJ70vYaD",
    "outputId": "bd616b1f-98a4-49b9-f86c-aa2e9a6e10de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/adagrad.py:138: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py:914: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 6501 vs previous value: 6501. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 17501 vs previous value: 17501. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 18301 vs previous value: 18301. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7f7438f973a0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn( x={\"X\": train_x_std}, y=train_y.to_numpy(), num_epochs=70, batch_size=50, shuffle=True)\n",
    "dnn_clf.train(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ozkKUCzvvY7b",
   "metadata": {
    "id": "ozkKUCzvvY7b"
   },
   "source": [
    "# Step 3: Predict for the test points using the model trained in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "EbjD6UXgvZBs",
   "metadata": {
    "id": "EbjD6UXgvZBs"
   },
   "outputs": [],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"X\": test_x_std}, y=test_y.to_numpy(), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "R5SD4-5bEnJN",
   "metadata": {
    "id": "R5SD4-5bEnJN"
   },
   "outputs": [],
   "source": [
    "y_pred_iter1 = dnn_clf.predict(input_fn=test_input_fn)\n",
    "y_pred1 = list(y_pred_iter1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pT2B094yv4o_",
   "metadata": {
    "id": "pT2B094yv4o_"
   },
   "source": [
    "# 5.2 Multi - Layer neural network\n",
    "\n",
    "---\n",
    "\n",
    "# Step 1: Implement a multi - layer neural network to classify the data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1-IqXvAiv48P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-IqXvAiv48P",
    "outputId": "5a0b54af-0b2b-4c8f-a9d8-ebfc55d72e69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp3xc1mrep\n"
     ]
    }
   ],
   "source": [
    "feature_cols2 = [tf.feature_column.numeric_column(\"X\", shape=[8])]\n",
    "\n",
    "dnn_clf2 = tf.estimator.DNNClassifier(hidden_units=[50, 70], n_classes=2,\n",
    "                                     feature_columns=feature_cols2, optimizer='Adagrad', activation_fn=tf.nn.relu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chE47ggUv5Cj",
   "metadata": {
    "id": "chE47ggUv5Cj"
   },
   "source": [
    "# Step 2: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "qLudrV1Mv5LK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLudrV1Mv5LK",
    "outputId": "852bc419-888d-4520-d96c-5238d609debb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1183 vs previous value: 1183. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1670 vs previous value: 1670. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7f736647fe20>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn2 = tf.estimator.inputs.numpy_input_fn(x={\"X\": train_x_std}, y=train_y.to_numpy(), num_epochs=100, batch_size=32, shuffle=True)\n",
    "dnn_clf2.train(input_fn=input_fn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-bGzeSaUv5S8",
   "metadata": {
    "id": "-bGzeSaUv5S8"
   },
   "source": [
    "# Step 3: Predict for the test points using the model trained in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "kggDlhMtv5ad",
   "metadata": {
    "id": "kggDlhMtv5ad"
   },
   "outputs": [],
   "source": [
    "test_input_fn2 = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": test_x_std}, y=test_y.to_numpy(), shuffle=False)\n",
    "\n",
    "\n",
    "y_pred_iter2 = dnn_clf2.predict(input_fn=test_input_fn2)\n",
    "y_pred2 = list(y_pred_iter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XT1hpdNiwLlh",
   "metadata": {
    "id": "XT1hpdNiwLlh"
   },
   "source": [
    "# 5.3 Multi - Layer neural network\n",
    "\n",
    "---\n",
    "\n",
    "# Step 1: Implement a multi - layer neural network to classify the data points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "t1JEqxkg48iA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1JEqxkg48iA",
    "outputId": "94c18ce7-1314-4cff-c979-843c3ace5dfb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpr0v98lhs\n"
     ]
    }
   ],
   "source": [
    "feature_cols3 = [tf.feature_column.numeric_column(\"X\", shape=[8])]\n",
    "\n",
    "dnn_clf3 = tf.estimator.DNNClassifier(hidden_units=[20, 50, 70], n_classes=2,\n",
    "                                     feature_columns=feature_cols3, optimizer='Adagrad', activation_fn=tf.nn.relu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OxVaoDxR4xNi",
   "metadata": {
    "id": "OxVaoDxR4xNi"
   },
   "source": [
    "Dense Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ntq2avYhwNL8",
   "metadata": {
    "id": "Ntq2avYhwNL8"
   },
   "source": [
    "# Step 2: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "tGHf8R_Xu-Qg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGHf8R_Xu-Qg",
    "outputId": "0555f3ad-129d-4ad8-9333-2fb3b9124b9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7f73666494c0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn3 = tf.estimator.inputs.numpy_input_fn(x={\"X\": train_x_std}, y=train_y.to_numpy(), num_epochs=100, batch_size=70, shuffle=True)\n",
    "dnn_clf3.train(input_fn=input_fn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "E02lDDiyIbVR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E02lDDiyIbVR",
    "outputId": "fb56e7ea-39c5-40b4-b666-727f5fffd6f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py:1175: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    }
   ],
   "source": [
    " y321 = dnn_clf3.train(input_fn=input_fn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9iiTn5CSIe1h",
   "metadata": {
    "id": "9iiTn5CSIe1h"
   },
   "outputs": [],
   "source": [
    " y321.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pZuLLFWGwNYw",
   "metadata": {
    "id": "pZuLLFWGwNYw"
   },
   "source": [
    "# Step 3: Predict for the test points using the model trained in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aUlxFb-mwNfg",
   "metadata": {
    "id": "aUlxFb-mwNfg"
   },
   "outputs": [],
   "source": [
    "test_input_fn3 = tf.estimator.inputs.numpy_input_fn(x={\"X\": test_x_std}, y=test_y.to_numpy(), shuffle=False)\n",
    "\n",
    "y_pred_iter3 = dnn_clf3.predict(input_fn=test_input_fn3)\n",
    "\n",
    "y_pred3 = list(y_pred_iter3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i6OBpYaWxxwG",
   "metadata": {
    "id": "i6OBpYaWxxwG"
   },
   "source": [
    "# 5.4 - Evaluation\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Comparing the accuracies of different Neural Network models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ry0jxD2Oxwq8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ry0jxD2Oxwq8",
    "outputId": "2e00d6c3-8ea3-4e57-92d6-469dd4318e62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/canned/head.py:635: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    }
   ],
   "source": [
    "eval_results = dnn_clf.evaluate(input_fn=test_input_fn)\n",
    "\n",
    "eval_results2 = dnn_clf2.evaluate(input_fn=test_input_fn2)\n",
    "\n",
    "eval_results3 = dnn_clf3.evaluate(input_fn=test_input_fn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1nOFYM5u1Oqe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nOFYM5u1Oqe",
    "outputId": "dc5b0ca3-76ec-4e48-9eb2-06fe026c002f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------Accuracy------------------------------------------ \n",
      "\n",
      "Accuracy of 5.1 Single Layer Neural Network: {'accuracy': 0.8115142, 'accuracy_baseline': 0.6422187, 'auc': 0.85850257, 'auc_precision_recall': 0.8211372, 'average_loss': 0.42337254, 'label/mean': 0.3577813, 'loss': 53.68364, 'precision': 0.8492408, 'prediction/mean': 0.34311828, 'recall': 0.57531226, 'global_step': 21303} %\n",
      "\n",
      "Accuracy of 5.2 Multi-Layer Nueral Network with 2 Hidden layers: {'accuracy': 0.8154574, 'accuracy_baseline': 0.6422187, 'auc': 0.8678451, 'auc_precision_recall': 0.8345132, 'average_loss': 0.41012752, 'label/mean': 0.3577813, 'loss': 52.00417, 'precision': 0.8501594, 'prediction/mean': 0.33578587, 'recall': 0.58780307, 'global_step': 47550} %\n",
      "\n",
      "Accuracy of 5.3 Multi-Layer Neural Network with 3 Hidden Layers {'accuracy': 0.8159832, 'accuracy_baseline': 0.6422187, 'auc': 0.85764724, 'auc_precision_recall': 0.82471716, 'average_loss': 0.4239928, 'label/mean': 0.3577813, 'loss': 53.762287, 'precision': 0.8557589, 'prediction/mean': 0.3290949, 'recall': 0.58412933, 'global_step': 21738} %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"------------------------------------------Accuracy------------------------------------------ \\n\")\n",
    "\n",
    "print(\"Accuracy of 5.1 Single Layer Neural Network: {} %\\n\".format(eval_results))\n",
    "print(\"Accuracy of 5.2 Multi-Layer Nueral Network with 2 Hidden layers: {} %\\n\".format(eval_results2))\n",
    "print(\"Accuracy of 5.3 Multi-Layer Neural Network with 3 Hidden Layers {} %\\n\".format(eval_results3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bXgMyWtEwo4K",
   "metadata": {
    "id": "bXgMyWtEwo4K"
   },
   "source": [
    "# Comparing the performances of models under sections 2, 3, 4 and 5 namely perceptron, descent procedure, SVM's and neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m-612AuiwqWP",
   "metadata": {
    "id": "m-612AuiwqWP"
   },
   "source": [
    "The maximum accuracies in different Sections:\n",
    "Perceptron : 64.88 %\n",
    "Polynomial Kernel SVM : 79.07%\n",
    "Neural Network: 81.59 %\n",
    "\n",
    "As you can see that, Neural Network performs the best due to its increased complexity of the model. It learns from the training dataset and passes it to different hidden layers to optimise the classification process and reduce errors in classification. The best performance amongst the Neural Network models was the one with 3 hidden layers with 20, 50, and 70 neurons in the hidden layers. It was run with 100 epochs and with a batch size of 32.\n",
    "\n",
    "SVM performs similarly to Neural Networks, although slightly performs lessere due to its less complex structure of the algorithm. SVM uses kernal trick to transform the feature space into a higher dimension to classify the datapoints accurately. SVM with the polynomial kernal outperforms other SVM models.\n",
    "\n",
    "Since the architecture of the perceptron is not complex enough to learn all the information of the features, the classfication accuracy takes a hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "on2TuI9GBRZD",
   "metadata": {
    "id": "on2TuI9GBRZD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
